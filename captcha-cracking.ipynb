{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing libraries\nimport os\nimport shutil\nimport glob\nimport random\nimport PIL\nimport time\nimport json\nimport cv2 as cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.image as img\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import img_to_array, ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:14:54.674925Z","iopub.execute_input":"2022-04-27T10:14:54.675472Z","iopub.status.idle":"2022-04-27T10:14:55.103937Z","shell.execute_reply.started":"2022-04-27T10:14:54.675433Z","shell.execute_reply":"2022-04-27T10:14:55.102938Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"os.mkdir('train')    ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:14:35.241878Z","iopub.execute_input":"2022-04-27T10:14:35.242562Z","iopub.status.idle":"2022-04-27T10:14:35.248700Z","shell.execute_reply.started":"2022-04-27T10:14:35.242524Z","shell.execute_reply":"2022-04-27T10:14:35.248022Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"What is Captcha (Completely Automated Public Turing test to Tell Computers and Humans Apart)???¶\nAccording to Wikipedia, a CAPTCHA is a type of challenge–response test used in computing to determine whether or not the user is human.\n\n\nHow does a CAPTCHA work?\nThe idea is that a computer program such as a bot will be unable to interpret the distorted letters, while a human being, who is used to seeing and interpreting letters in all kinds of contexts – different fonts, different handwritings, etc. – will usually be able to identify them.\n\nCAPTCHAs were designed to prevent computers from automatically filling out forms by verifying that you are a real person. But with the rise of deep learning and computer vision, they can now often be defeated easily.\n","metadata":{}},{"cell_type":"code","source":"DATA_DIR='../input/captcha-version-2-images/samples/*png'\nH,W,C=200,50,1\nN_LABELS=128\nD=5\nlabel=[]\nimage=[]\nimage_list=[f for f in glob.glob(DATA_DIR,recursive=True)]   \nfor i in image_list:\n    l=str(i).split('/')[-1].replace('.png','')\n    im=str(i)\n    label.append(l)\n    image.append(im)\ndf=pd.DataFrame(columns=['image','label'])  \ndf['image']=image\ndf['label']=label\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:15:03.086839Z","iopub.execute_input":"2022-04-27T10:15:03.087427Z","iopub.status.idle":"2022-04-27T10:15:03.479712Z","shell.execute_reply.started":"2022-04-27T10:15:03.087364Z","shell.execute_reply":"2022-04-27T10:15:03.479009Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#shape \ncv2.imread(df['image'][1],cv2.IMREAD_GRAYSCALE).shape","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:15:07.992868Z","iopub.execute_input":"2022-04-27T10:15:07.993622Z","iopub.status.idle":"2022-04-27T10:15:08.037578Z","shell.execute_reply.started":"2022-04-27T10:15:07.993586Z","shell.execute_reply":"2022-04-27T10:15:08.036828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n\nfig=plt.figure(figsize=(10.00,10.50))\n#plt.rcParams[\"figure.autolayout\"] = True\nfig.suptitle(' Preprocessed images ', fontsize=50)\nimg1=cv2.imread(df['image'][1],cv2.IMREAD_GRAYSCALE)\nimg2=cv2.imread(df['image'][2],cv2.IMREAD_GRAYSCALE)\nimga1 = cv2.adaptiveThreshold(img1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\nimga2=cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\nkernel = np.ones((5,5),np.uint8)\nimagew1 = cv2.morphologyEx(imga1, cv2.MORPH_CLOSE, kernel)\nimagew2 = cv2.morphologyEx(imga2, cv2.MORPH_CLOSE, kernel)\nkernel = np.ones((2,2),np.uint8)\nimaged1= cv2.dilate(imagew1, kernel, iterations = 1)\nimaged2 = cv2.dilate(imagew2, kernel, iterations = 1)\nimagesharp1 = cv2.GaussianBlur(imaged1, (5,5), 0) \nimagesharp2 = cv2.GaussianBlur(imaged2, (5,5), 0) \nplt.subplot(10, 2, 1)\nplt.title('Greyscaled image 1')\nplt.imshow(img1)\nplt.subplot(10, 2, 2)\nplt.title('Greyscaled image 2')\nplt.imshow(img2)\nplt.subplot(10, 2, 3)\nplt.title('Adaptive thresholding image 1')\nplt.imshow(imga1)\nplt.subplot(10, 2, 4)\nplt.title('Adaptive thresholding image 2')\nplt.imshow(imga2)\nplt.subplot(10, 2, 5)\nplt.title('MropholgyEx image 1')\nplt.imshow(imagew1)\nplt.subplot(10, 2, 6)\nplt.title('MoropholgyEx image 2')\nplt.imshow(imagew2)\nplt.subplot(10, 2, 7)\nplt.title('Dilated image 1')\nplt.imshow(imaged1)\nplt.subplot(10, 2, 8)\nplt.title('Dilated image 2')\nplt.imshow(imaged2)\nplt.subplot(10, 2, 9)\nplt.title('Gaussian blur image 1')\nplt.imshow(imagesharp1, cmap=\"Blues_r\")\nplt.subplot(10, 2, 10)\nplt.title('Gaussian blur image 2')\nplt.imshow(imagesharp2, cmap=\"Accent_r\")\nplt.show() \n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:15:17.042822Z","iopub.execute_input":"2022-04-27T10:15:17.043256Z","iopub.status.idle":"2022-04-27T10:15:18.215173Z","shell.execute_reply.started":"2022-04-27T10:15:17.043218Z","shell.execute_reply":"2022-04-27T10:15:18.214474Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom PIL import Image\nimages=[]\nlabels=[]\n\nvocabulary = {'2','3','4','5','6','7','8','b','c','d','e','f','g','m','n','p','w','x','y'}\nchar_to_num = {'2':0,'3':1,'4':2,'5':3,'6':4,'7':5,'8':6,'b':7,'c':8,'d':9,'e':10,'f':11,'g':12,'m':13,'n':14,'p':15,'w':16,'x':17,'y':18}\n\nfor i in df['image']:\n            \n           \n            im = cv2.imread(i,cv2.IMREAD_GRAYSCALE)\n            im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n            \n            im = cv2.adaptiveThreshold(im, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n            kernel = np.ones((5,5),np.uint8)\n            imagew = cv2.morphologyEx(im, cv2.MORPH_CLOSE, kernel)\n            kernel = np.ones((2,2),np.uint8)\n            imagew = cv2.dilate(imagew, kernel, iterations = 1)\n            imagesharp = cv2.GaussianBlur(imagew, (5,5), 0)\n        \n            \n            im=np.array(imagesharp) / 255.0\n            images.append(im)\nfor i in df['label']:\n      label = list(map(lambda x:char_to_num[x], i))\n      labels.append(label)\n     # l'abels.append([to_categorical(ord(i_n), N_LABELS) for i_n in i])\n#converting to array for feeding to model        \nX=np.array(images)\ny=np.array(labels)       \nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)                    \nx_train = np.expand_dims(X_train, -1)\nx_test=np.expand_dims(X_test, -1)\n            ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:15:53.337074Z","iopub.execute_input":"2022-04-27T10:15:53.337770Z","iopub.status.idle":"2022-04-27T10:16:01.221531Z","shell.execute_reply.started":"2022-04-27T10:15:53.337733Z","shell.execute_reply":"2022-04-27T10:16:01.220483Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n# Let's create a new CTCLayer by subclassing\n#CTC layer creation\nclass CTCLayer(layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        # Compute the training-time loss value and add it to the layer using `self.add_loss()`.\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        # At test time, just return the computed predictions\n        return y_pred\n\ndef build_model():\n    \n    # Inputs to the model\n    input_img = layers.Input(shape=(200,50,1), name=\"image\", dtype=\"float32\") \n    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n\n    # First conv block\n    x = layers.Conv2D(32,(3, 3),activation=\"relu\",kernel_initializer=\"he_normal\",padding=\"same\",name=\"Conv1\")(input_img)\n    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n\n    # Second conv block\n    x = layers.Conv2D(64,(3, 3),activation=\"relu\",kernel_initializer=\"he_normal\",padding=\"same\",name=\"Conv2\")(x)\n    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n\n    # We have used two max pool with pool size and strides 2.\n    # Hence, downsampled feature maps are 4x smaller. The number of\n    # filters in the last layer is 64. Reshape accordingly before\n    # passing the output to the RNN part of the model \n    x = layers.Reshape(target_shape=(50, 768), name=\"reshape\")(x)\n  \n    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n    x = layers.Dropout(0.2)(x)\n\n    # RNNs\n    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n\n    # Output layer\n    x = layers.Dense(20, activation=\"softmax\", name=\"dense2\")(x) # 20 = 19 characters + UKN\n\n    # Add CTC layer for calculating CTC loss at each step\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    # Define the model\n    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"captcha_cracking\")\n   \n    # Compile the model and return\n    model.compile(optimizer=keras.optimizers.Adam())\n    return model\n\n\n# Get the model\nmodel = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:16:33.214163Z","iopub.execute_input":"2022-04-27T10:16:33.214479Z","iopub.status.idle":"2022-04-27T10:16:37.144086Z","shell.execute_reply.started":"2022-04-27T10:16:33.214446Z","shell.execute_reply":"2022-04-27T10:16:37.143407Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"es = keras.callbacks.EarlyStopping(monitor='val_loss',\n                                   patience=5,\n                                   restore_best_weights=True)\n\nbatch_size = 64\nvalid_batch_size = 64\nmodel_np=model.fit([x_train,y_train],epochs=50, validation_data=[x_test, y_test],shuffle=True,callbacks=[es])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:16:59.636025Z","iopub.execute_input":"2022-04-27T10:16:59.636634Z","iopub.status.idle":"2022-04-27T10:17:53.216794Z","shell.execute_reply.started":"2022-04-27T10:16:59.636596Z","shell.execute_reply":"2022-04-27T10:17:53.216082Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.evaluate([x_test, y_test], batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:18:15.238203Z","iopub.execute_input":"2022-04-27T10:18:15.238482Z","iopub.status.idle":"2022-04-27T10:18:26.089503Z","shell.execute_reply.started":"2022-04-27T10:18:15.238451Z","shell.execute_reply":"2022-04-27T10:18:26.088834Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(model_np.history['loss'])\nplt.plot(model_np.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:18:30.807072Z","iopub.execute_input":"2022-04-27T10:18:30.807666Z","iopub.status.idle":"2022-04-27T10:18:31.004610Z","shell.execute_reply.started":"2022-04-27T10:18:30.807628Z","shell.execute_reply":"2022-04-27T10:18:31.003880Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.save('captchamodel.h5')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:18:56.419919Z","iopub.execute_input":"2022-04-27T10:18:56.420795Z","iopub.status.idle":"2022-04-27T10:18:56.492739Z","shell.execute_reply.started":"2022-04-27T10:18:56.420754Z","shell.execute_reply":"2022-04-27T10:18:56.491993Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:42:19.745057Z","iopub.execute_input":"2022-02-22T17:42:19.745288Z","iopub.status.idle":"2022-02-22T17:42:19.773087Z","shell.execute_reply.started":"2022-02-22T17:42:19.745259Z","shell.execute_reply":"2022-02-22T17:42:19.771731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnum_to_char = {'-1':'UKN','0':'2','1':'3','2':'4','3':'5','4':'6','5':'7','6':'8','7':'b','8':'c','9':'d','10':'e','11':'f','12':'g','13':'m','14':'n','15':'p','16':'w','17':'x','18':'y'}\nprediction_model = keras.models.Model(\n    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n)\nfor i in range(10):\n        y_pred = prediction_model.predict(np.expand_dims(x_test[i], axis=0))\n        y_pred = keras.backend.ctc_decode(y_pred , input_length=np.ones(1)*50, greedy=True) # decoding -> y_pred[0].shape = (104,5)\n        y_pred = y_pred[0][0][0:104,0:5].numpy() \n        print(f\"predicted :{str(list(map(lambda x:num_to_char[str(x)], y_pred[0])))},actual :{str(list(map(lambda x:num_to_char[str(x)], y_test[i])))} \")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:19:09.882813Z","iopub.execute_input":"2022-04-27T10:19:09.883104Z","iopub.status.idle":"2022-04-27T10:19:11.479134Z","shell.execute_reply.started":"2022-04-27T10:19:09.883072Z","shell.execute_reply":"2022-04-27T10:19:11.478364Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### optimization","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n# Let's create a new CTCLayer by subclassing\nclass CTCLayer(layers.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred):\n        # Compute the training-time loss value and add it to the layer using `self.add_loss()`.\n        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n\n        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n\n        # At test time, just return the computed predictions\n        return y_pred\n\ndef build_model(hp):\n    \n    # Inputs to the model\n    input_img = layers.Input(shape=(200,50,1), name=\"image\", dtype=\"float32\") \n    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n\n    # First conv block\n    x = layers.Conv2D(32,(3, 3),activation=\"relu\",kernel_initializer=\"he_normal\",padding=\"same\",name=\"Conv1\")(input_img)\n    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n\n    # Second conv block\n    x = layers.Conv2D(64,(3, 3),activation=\"relu\",kernel_initializer=\"he_normal\",padding=\"same\",name=\"Conv2\")(x)\n    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n\n    # We have used two max pool with pool size and strides 2.\n    # Hence, downsampled feature maps are 4x smaller. The number of\n    # filters in the last layer is 64. Reshape accordingly before\n    # passing the output to the RNN part of the model \n    x = layers.Reshape(target_shape=(50, 768), name=\"reshape\")(x)\n  \n    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n    x = layers.Dropout(0.2)(x)\n\n    # RNNs\n    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n\n    # Output layer\n    x = layers.Dense(20, activation=\"softmax\", name=\"dense2\")(x) # 20 = 19 characters + UKN\n\n    # Add CTC layer for calculating CTC loss at each step\n    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n\n    # Define the model\n    model = keras.models.Model(inputs=[input_img, labels], outputs=output, name=\"captcha_cracking\")\n    hp_l=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    # Compile the model and return\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_l))\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:25:02.020211Z","iopub.execute_input":"2022-04-27T10:25:02.020464Z","iopub.status.idle":"2022-04-27T10:25:02.035571Z","shell.execute_reply.started":"2022-04-27T10:25:02.020435Z","shell.execute_reply":"2022-04-27T10:25:02.034885Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import keras_tuner as kt\ntuner = kt.tuners.BayesianOptimization(\n    build_model,\n    objective='val_loss',max_trials=1,overwrite=True\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:32:24.124442Z","iopub.execute_input":"2022-04-27T10:32:24.125203Z","iopub.status.idle":"2022-04-27T10:32:25.296786Z","shell.execute_reply.started":"2022-04-27T10:32:24.125155Z","shell.execute_reply":"2022-04-27T10:32:25.296080Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tuner.search([x_train,y_train],epochs=100, validation_data=[x_test, y_test])\nbest_model = tuner.get_best_models()[0]\nbest_hyperparameters = tuner.get_best_hyperparameters(1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:32:28.087813Z","iopub.execute_input":"2022-04-27T10:32:28.088576Z","iopub.status.idle":"2022-04-27T10:34:09.633397Z","shell.execute_reply.started":"2022-04-27T10:32:28.088527Z","shell.execute_reply":"2022-04-27T10:34:09.632675Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model_op=tuner.hypermodel.build(best_hyperparameters)\nmodel_op.summary()\nmodel_p=model_op.fit([x_train,y_train],epochs=50, validation_data=[x_test, y_test],shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T10:35:12.737503Z","iopub.execute_input":"2022-04-27T10:35:12.737759Z","iopub.status.idle":"2022-04-27T10:37:36.463863Z","shell.execute_reply.started":"2022-04-27T10:35:12.737731Z","shell.execute_reply":"2022-04-27T10:37:36.463167Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(model_p.history['loss'])\nplt.plot(model_p.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:42:19.787019Z","iopub.status.idle":"2022-02-22T17:42:19.787478Z","shell.execute_reply.started":"2022-02-22T17:42:19.787217Z","shell.execute_reply":"2022-02-22T17:42:19.787239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_to_char = {'-1':'UKN','0':'2','1':'3','2':'4','3':'5','4':'6','5':'7','6':'8','7':'b','8':'c','9':'d','10':'e','11':'f','12':'g','13':'m','14':'n','15':'p','16':'w','17':'x','18':'y'}\nprediction_model = keras.models.Model(\n    model_op.get_layer(name=\"image\").input, model_op.get_layer(name=\"dense2\").output\n)\nprediction_model.summary()\nfor i in range(10):\n    \n    y_pred = prediction_model.predict(np.expand_dims(x_test[13], axis=0))\n    print(y_pred.shape)\n    y_pred = keras.backend.ctc_decode(y_pred , input_length=np.ones(1)*50, greedy=True) # decoding -> y_pred[0].shape = (104,5)\n    y_pred = y_pred[0][0][0:104,0:5].numpy() \n    print(y_pred)\n    print(f\"predicted :{str(list(map(lambda x:num_to_char[str(x)], y_pred[0])))},actual :{str(list(map(lambda x:num_to_char[str(x)], y_test[13])))} \")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-22T17:42:19.788589Z","iopub.status.idle":"2022-02-22T17:42:19.789416Z","shell.execute_reply.started":"2022-02-22T17:42:19.789145Z","shell.execute_reply":"2022-02-22T17:42:19.789174Z"},"trusted":true},"execution_count":null,"outputs":[]}]}